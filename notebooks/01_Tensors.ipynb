{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04cfe770-33be-46f5-aae8-d1c08eec20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71467b3c-2318-45d3-9d2b-fdc8feb8bd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.ones(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9edbaf7-ed9b-4fe9-9b36-f031f13bba06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d948fc-687f-4b9a-a1b3-e41bcc977cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3cc1bce-7453-4e6f-bc7e-dc1609a3ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c14d4d9-4f0b-40aa-a9de-c1bdd1f5d084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2126],\n",
       "        [0.7152],\n",
       "        [0.0722]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b34b0cd-3a1e-4c3a-a433-a7b291a59bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "unsqueeze(dim) -> Tensor\n",
       "\n",
       "See :func:`torch.unsqueeze`\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights.unsqueeze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d0eab78-e9e6-405d-88d7-9fd52a63cf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2126, 0.7152, 0.0722]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "974d306c-ae7c-4da6-a19e-d086286edad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81cc90ef-8cab-4bf2-8c35-9b71e3945473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2126]],\n",
       "\n",
       "        [[0.7152]],\n",
       "\n",
       "        [[0.0722]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cedc916-67d6-464f-ac7b-310f7016ea34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inigo/dl/2020-dlwpt/.venv/lib/python3.10/site-packages/torch/_tensor.py:1105: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1758.)\n",
      "  return super(Tensor, self).refine_names(names)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8036, -0.9316, -0.6373, -1.4347,  0.9375],\n",
       "         [ 0.8515, -0.1080, -1.0595,  1.4778, -0.1260],\n",
       "         [ 0.1127,  0.2497,  2.3881,  0.2079,  0.4195],\n",
       "         [ 0.2861, -0.8131, -1.3408,  0.8461,  0.5869],\n",
       "         [-0.3661,  0.7606,  1.5774, -1.8758,  1.0469]],\n",
       "\n",
       "        [[ 0.1742, -1.6002, -0.5357,  0.8952,  0.6416],\n",
       "         [ 0.3047, -0.3877, -0.0499, -0.6046,  0.9074],\n",
       "         [ 0.0484,  0.6979,  1.4784,  1.0756,  0.7823],\n",
       "         [-0.5834,  1.9722,  0.6251,  2.8408, -0.9974],\n",
       "         [-0.7189, -0.0068, -0.4164,  0.1541, -0.4887]],\n",
       "\n",
       "        [[ 1.6945, -0.0338,  1.2907,  0.0141,  0.3737],\n",
       "         [ 0.4069, -0.2132,  0.0646, -0.2493, -0.8528],\n",
       "         [ 0.2917, -0.7763,  0.7214, -0.2477, -0.3638],\n",
       "         [-1.6562,  1.6603, -0.8035,  0.3702, -0.9543],\n",
       "         [-0.6786, -0.6274,  0.0695,  1.6595,  2.1415]]],\n",
       "       names=('channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t.refine_names(..., 'channels', 'rows', 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c61c4112-f641-48fb-ada2-9dc56cdb8a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8036, -0.9316, -0.6373, -1.4347,  0.9375],\n",
       "         [ 0.8515, -0.1080, -1.0595,  1.4778, -0.1260],\n",
       "         [ 0.1127,  0.2497,  2.3881,  0.2079,  0.4195],\n",
       "         [ 0.2861, -0.8131, -1.3408,  0.8461,  0.5869],\n",
       "         [-0.3661,  0.7606,  1.5774, -1.8758,  1.0469]],\n",
       "\n",
       "        [[ 0.1742, -1.6002, -0.5357,  0.8952,  0.6416],\n",
       "         [ 0.3047, -0.3877, -0.0499, -0.6046,  0.9074],\n",
       "         [ 0.0484,  0.6979,  1.4784,  1.0756,  0.7823],\n",
       "         [-0.5834,  1.9722,  0.6251,  2.8408, -0.9974],\n",
       "         [-0.7189, -0.0068, -0.4164,  0.1541, -0.4887]],\n",
       "\n",
       "        [[ 1.6945, -0.0338,  1.2907,  0.0141,  0.3737],\n",
       "         [ 0.4069, -0.2132,  0.0646, -0.2493, -0.8528],\n",
       "         [ 0.2917, -0.7763,  0.7214, -0.2477, -0.3638],\n",
       "         [-1.6562,  1.6603, -0.8035,  0.3702, -0.9543],\n",
       "         [-0.6786, -0.6274,  0.0695,  1.6595,  2.1415]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e09ec9-1188-4c8d-b8ca-582e7c5c4243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00789498-475e-452d-a61c-d1f57074d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_weights = (img_t * unsqueezed_weights)\n",
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL with PyTorch (3.10)",
   "language": "python",
   "name": "dlwpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
