{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48146/1646494204.py:2: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1758.)\n",
      "  _ = torch.tensor([0.2126, 0.7152, 0.0722], names=['c'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "_ = torch.tensor([0.2126, 0.7152, 0.0722], names=['c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive = img_t.mean(-3)\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive.shape, batch_gray_naive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    "img_weights = (img_t * unsqueezed_weights)\n",
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\n",
    "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
    "batch_gray_weighted_fancy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5831, -0.4238,  0.3105, -1.3146,  0.4923],\n",
       "         [ 0.0784,  0.2893, -1.2461,  1.1088, -0.3600],\n",
       "         [-0.7937,  0.8938,  0.5185, -0.3799, -0.3460],\n",
       "         [ 0.8064,  0.4486,  1.2623, -0.8450,  0.8281],\n",
       "         [-0.8567,  1.7735, -2.4414,  1.1648, -1.0989]],\n",
       "\n",
       "        [[ 2.5220, -1.3231, -0.8238, -0.0152,  0.2151],\n",
       "         [-0.7359, -1.9474, -0.4078, -0.8671, -0.7557],\n",
       "         [ 1.0370,  0.7249,  0.3325,  1.2125, -0.6980],\n",
       "         [ 0.6929, -0.1641,  1.4682, -0.3090,  1.0413],\n",
       "         [ 1.0770, -0.2593,  1.3552, -0.2441,  0.6417]],\n",
       "\n",
       "        [[ 0.2387,  0.6139, -0.0387,  0.5136, -0.0392],\n",
       "         [-0.9932,  0.0913, -0.4339,  0.5757, -1.1833],\n",
       "         [-0.1101, -0.4281, -0.3595, -1.8122,  2.8633],\n",
       "         [-1.0104, -0.6954,  0.0087,  0.3208,  0.4111],\n",
       "         [ 0.3775,  1.4174, -0.1036, -1.0930,  0.6621]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1976, -1.5603, -0.0045, -1.2572,  0.5885],\n",
       "          [-0.1003,  0.3111,  0.9989,  1.0852,  1.2955],\n",
       "          [ 1.3837,  0.4713,  0.4735, -0.6076, -0.7892],\n",
       "          [-0.7479, -0.1799, -0.9949, -0.9648, -0.6326],\n",
       "          [-0.8645, -1.3328,  1.3083, -0.7171, -0.5308]],\n",
       "\n",
       "         [[ 0.6961, -0.3234, -0.9508,  1.0607,  0.6286],\n",
       "          [-0.2541, -0.3004,  0.1852,  0.0747,  0.5703],\n",
       "          [-1.2282,  2.1270, -0.7372, -0.1612, -0.6412],\n",
       "          [ 0.3244, -2.0292, -0.7470, -0.3488,  0.3402],\n",
       "          [-1.5664,  0.8073, -0.8727,  3.4147, -1.4600]],\n",
       "\n",
       "         [[-1.2205,  0.1338,  0.3889,  0.7897, -0.6711],\n",
       "          [ 0.7180,  0.6707, -1.0545, -0.5493, -0.4668],\n",
       "          [-0.2094,  1.0718, -1.0343, -1.0147, -1.0359],\n",
       "          [-0.5542,  0.2617, -0.4181, -1.0775, -0.2654],\n",
       "          [ 0.5455,  0.2202,  1.7382, -1.2776,  0.2460]]],\n",
       "\n",
       "\n",
       "        [[[-0.6350,  1.4596, -1.9408, -0.4513,  0.2957],\n",
       "          [-0.8001,  2.0459, -0.3588, -0.0855, -1.0849],\n",
       "          [-1.1966,  0.5091,  0.3842, -0.6459, -1.8032],\n",
       "          [ 0.5243, -0.8754, -0.8962,  0.9342,  0.5710],\n",
       "          [-0.8713,  0.2111,  0.4242,  0.3454, -0.9917]],\n",
       "\n",
       "         [[ 1.1977, -0.5739,  1.3035,  0.2861, -0.4183],\n",
       "          [ 0.5366,  0.1142,  0.8873,  0.0803,  0.8160],\n",
       "          [-0.2250,  0.2202, -0.2575,  1.9680,  0.0990],\n",
       "          [-0.7868, -0.4735, -1.5526, -1.9224, -0.4760],\n",
       "          [ 1.4856,  1.0442, -0.9838, -0.9782, -2.8005]],\n",
       "\n",
       "         [[ 1.3456, -0.2302,  0.0522,  0.7289,  1.2271],\n",
       "          [ 0.2656, -0.1841, -0.1974,  0.8634, -0.8859],\n",
       "          [ 1.1105,  1.3772,  0.4398,  0.4734, -0.4649],\n",
       "          [ 0.3053, -1.0785,  0.1186,  1.6373, -0.2031],\n",
       "          [ 1.3385, -1.1387,  2.2375,  0.0200, -1.7845]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_named.rename(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1976, -1.5603, -0.0045, -1.2572,  0.5885],\n",
       "          [-0.1003,  0.3111,  0.9989,  1.0852,  1.2955],\n",
       "          [ 1.3837,  0.4713,  0.4735, -0.6076, -0.7892],\n",
       "          [-0.7479, -0.1799, -0.9949, -0.9648, -0.6326],\n",
       "          [-0.8645, -1.3328,  1.3083, -0.7171, -0.5308]],\n",
       "\n",
       "         [[ 0.6961, -0.3234, -0.9508,  1.0607,  0.6286],\n",
       "          [-0.2541, -0.3004,  0.1852,  0.0747,  0.5703],\n",
       "          [-1.2282,  2.1270, -0.7372, -0.1612, -0.6412],\n",
       "          [ 0.3244, -2.0292, -0.7470, -0.3488,  0.3402],\n",
       "          [-1.5664,  0.8073, -0.8727,  3.4147, -1.4600]],\n",
       "\n",
       "         [[-1.2205,  0.1338,  0.3889,  0.7897, -0.6711],\n",
       "          [ 0.7180,  0.6707, -1.0545, -0.5493, -0.4668],\n",
       "          [-0.2094,  1.0718, -1.0343, -1.0147, -1.0359],\n",
       "          [-0.5542,  0.2617, -0.4181, -1.0775, -0.2654],\n",
       "          [ 0.5455,  0.2202,  1.7382, -1.2776,  0.2460]]],\n",
       "\n",
       "\n",
       "        [[[-0.6350,  1.4596, -1.9408, -0.4513,  0.2957],\n",
       "          [-0.8001,  2.0459, -0.3588, -0.0855, -1.0849],\n",
       "          [-1.1966,  0.5091,  0.3842, -0.6459, -1.8032],\n",
       "          [ 0.5243, -0.8754, -0.8962,  0.9342,  0.5710],\n",
       "          [-0.8713,  0.2111,  0.4242,  0.3454, -0.9917]],\n",
       "\n",
       "         [[ 1.1977, -0.5739,  1.3035,  0.2861, -0.4183],\n",
       "          [ 0.5366,  0.1142,  0.8873,  0.0803,  0.8160],\n",
       "          [-0.2250,  0.2202, -0.2575,  1.9680,  0.0990],\n",
       "          [-0.7868, -0.4735, -1.5526, -1.9224, -0.4760],\n",
       "          [ 1.4856,  1.0442, -0.9838, -0.9782, -2.8005]],\n",
       "\n",
       "         [[ 1.3456, -0.2302,  0.0522,  0.7289,  1.2271],\n",
       "          [ 0.2656, -0.1841, -0.1974,  0.8634, -0.8859],\n",
       "          [ 1.1105,  1.3772,  0.4398,  0.4734, -0.4649],\n",
       "          [ 0.3053, -1.0785,  0.1186,  1.6373, -0.2031],\n",
       "          [ 1.3385, -1.1387,  2.2375,  0.0200, -1.7845]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "img_named =  img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print(\"img named:\", img_named.shape, img_named.names)\n",
    "print(\"batch named:\", batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_aligned = weights_named.align_as(img_named)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 1]), ('channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_aligned.shape, weights_aligned.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gray_named = (img_named[..., :3] * weights_named).sum('channels')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), (None, None))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_plain = gray_named.rename(None)\n",
    "gray_plain.shape, gray_plain.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL with PyTorch (3.10)",
   "language": "python",
   "name": "dlwpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
